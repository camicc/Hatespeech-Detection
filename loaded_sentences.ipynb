{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BBT' 'FRIENDS' 'GOLDENGIRLS' 'SARCASMOHOLICS']\n"
     ]
    }
   ],
   "source": [
    "# JE CROIS QU?ON MEME PAS BESOIN DE CETTE CELLULE\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Open the JSON file\n",
    "with open('data/sarcasm_data.json', 'r') as file: # ADD in readme to place the data in a folder data\n",
    "    # Load JSON data from the file\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Define a list of labels to extract\n",
    "labels = ['utterance', 'speaker', 'context', 'context_speakers', 'show', 'sarcasm']\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame(columns=labels)\n",
    "\n",
    "# Iterate over each key-value pair in the JSON data\n",
    "for key, value in json_data.items():\n",
    "    # Extract only the desired labels from the JSON data and add a new row to the DataFrame\n",
    "    row_data = {label: value[label] for label in labels}\n",
    "    df.loc[len(df)] = row_data\n",
    "\n",
    "# Now 'df' is a DataFrame with the desired columns\n",
    "print(df.show.unique()) # This line might not be necessary for the final notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>speaker</th>\n",
       "      <th>context</th>\n",
       "      <th>context_speakers</th>\n",
       "      <th>show</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>sentiment_context_all</th>\n",
       "      <th>sentiment_context_per_sentence</th>\n",
       "      <th>sentiment_utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's just a privilege to watch your mind at work.</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>[I never would have identified the fingerprint...</td>\n",
       "      <td>[LEONARD, SHELDON]</td>\n",
       "      <td>BBT</td>\n",
       "      <td>True</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>[{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't think I'll be able to stop thinking ab...</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>[This is one of my favorite places to kick bac...</td>\n",
       "      <td>[HOWARD, PENNY, HOWARD, HOWARD, HOWARD, PENNY,...</td>\n",
       "      <td>BBT</td>\n",
       "      <td>True</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.871, 'pos': 0.129, 'comp...</td>\n",
       "      <td>[{'neg': 0.0, 'neu': 0.705, 'pos': 0.295, 'com...</td>\n",
       "      <td>{'neg': 0.18, 'neu': 0.82, 'pos': 0.0, 'compou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since it's not bee season, you can have my epi...</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>[Here we go. Pad thai, no peanuts., But does i...</td>\n",
       "      <td>[LEONARD, HOWARD, LEONARD]</td>\n",
       "      <td>BBT</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg': 0.143, 'neu': 0.857, 'pos': 0.0, 'comp...</td>\n",
       "      <td>[{'neg': 0.268, 'neu': 0.732, 'pos': 0.0, 'com...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lois Lane is falling, accelerating at an initi...</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>[A marathon? How many Superman movies are ther...</td>\n",
       "      <td>[PENNY, SHELDON, PENNY, SHELDON, SHELDON, PENN...</td>\n",
       "      <td>BBT</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.906, 'pos': 0.094, 'comp...</td>\n",
       "      <td>[{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...</td>\n",
       "      <td>{'neg': 0.058, 'neu': 0.851, 'pos': 0.091, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm just inferring this is a couch because the...</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>[Great Caesar's ghost, look at this place., So...</td>\n",
       "      <td>[SHELDON, LEONARD, SHELDON, SHELDON, SHELDON, ...</td>\n",
       "      <td>BBT</td>\n",
       "      <td>True</td>\n",
       "      <td>{'neg': 0.097, 'neu': 0.815, 'pos': 0.088, 'co...</td>\n",
       "      <td>[{'neg': 0.202, 'neu': 0.439, 'pos': 0.36, 'co...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>Hes not right for the part, and if I suggest h...</td>\n",
       "      <td>CHANDLER</td>\n",
       "      <td>[What am I gonna do now?, Just pass the tape a...</td>\n",
       "      <td>[CHANDLER, RACHEL]</td>\n",
       "      <td>FRIENDS</td>\n",
       "      <td>True</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>[{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...</td>\n",
       "      <td>{'neg': 0.102, 'neu': 0.898, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>Oh yeah he has a caretaker his older brother, ...</td>\n",
       "      <td>CHANDLER</td>\n",
       "      <td>[Helo! Anybody in there order a celebrity?, Wh...</td>\n",
       "      <td>[JOEY, PERSON, CHANDLER, PERSON]</td>\n",
       "      <td>FRIENDS</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg': 0.062, 'neu': 0.751, 'pos': 0.187, 'co...</td>\n",
       "      <td>[{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.858, 'pos': 0.142, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Is it me or the greetings gone downhill around...</td>\n",
       "      <td>CHANDLER</td>\n",
       "      <td>[Hey, You son of a bitch!]</td>\n",
       "      <td>[CHANDLER, JOEY]</td>\n",
       "      <td>FRIENDS</td>\n",
       "      <td>True</td>\n",
       "      <td>{'neg': 0.506, 'neu': 0.494, 'pos': 0.0, 'comp...</td>\n",
       "      <td>[{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.763, 'pos': 0.237, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>You are right, by saying nice, I am virtually ...</td>\n",
       "      <td>CHANDLER</td>\n",
       "      <td>[Did I go to this school?, Hey, there's Missy ...</td>\n",
       "      <td>[CHANDLER, ROSS, CHANDLER, ROSS]</td>\n",
       "      <td>FRIENDS</td>\n",
       "      <td>True</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>[{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.781, 'pos': 0.219, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Yes and we are \"very\" excited about it.</td>\n",
       "      <td>CHANDLER</td>\n",
       "      <td>[Anyway, if you don't feel like being alone to...</td>\n",
       "      <td>[ROSS]</td>\n",
       "      <td>FRIENDS</td>\n",
       "      <td>True</td>\n",
       "      <td>{'neg': 0.159, 'neu': 0.736, 'pos': 0.105, 'co...</td>\n",
       "      <td>[{'neg': 0.159, 'neu': 0.736, 'pos': 0.105, 'c...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.527, 'pos': 0.473, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             utterance   speaker  \\\n",
       "0    It's just a privilege to watch your mind at work.   SHELDON   \n",
       "1    I don't think I'll be able to stop thinking ab...     PENNY   \n",
       "2    Since it's not bee season, you can have my epi...   SHELDON   \n",
       "3    Lois Lane is falling, accelerating at an initi...   SHELDON   \n",
       "4    I'm just inferring this is a couch because the...   SHELDON   \n",
       "..                                                 ...       ...   \n",
       "685  Hes not right for the part, and if I suggest h...  CHANDLER   \n",
       "686  Oh yeah he has a caretaker his older brother, ...  CHANDLER   \n",
       "687  Is it me or the greetings gone downhill around...  CHANDLER   \n",
       "688  You are right, by saying nice, I am virtually ...  CHANDLER   \n",
       "689            Yes and we are \"very\" excited about it.  CHANDLER   \n",
       "\n",
       "                                               context  \\\n",
       "0    [I never would have identified the fingerprint...   \n",
       "1    [This is one of my favorite places to kick bac...   \n",
       "2    [Here we go. Pad thai, no peanuts., But does i...   \n",
       "3    [A marathon? How many Superman movies are ther...   \n",
       "4    [Great Caesar's ghost, look at this place., So...   \n",
       "..                                                 ...   \n",
       "685  [What am I gonna do now?, Just pass the tape a...   \n",
       "686  [Helo! Anybody in there order a celebrity?, Wh...   \n",
       "687                         [Hey, You son of a bitch!]   \n",
       "688  [Did I go to this school?, Hey, there's Missy ...   \n",
       "689  [Anyway, if you don't feel like being alone to...   \n",
       "\n",
       "                                      context_speakers     show sarcasm  \\\n",
       "0                                   [LEONARD, SHELDON]      BBT    True   \n",
       "1    [HOWARD, PENNY, HOWARD, HOWARD, HOWARD, PENNY,...      BBT    True   \n",
       "2                           [LEONARD, HOWARD, LEONARD]      BBT   False   \n",
       "3    [PENNY, SHELDON, PENNY, SHELDON, SHELDON, PENN...      BBT   False   \n",
       "4    [SHELDON, LEONARD, SHELDON, SHELDON, SHELDON, ...      BBT    True   \n",
       "..                                                 ...      ...     ...   \n",
       "685                                 [CHANDLER, RACHEL]  FRIENDS    True   \n",
       "686                   [JOEY, PERSON, CHANDLER, PERSON]  FRIENDS   False   \n",
       "687                                   [CHANDLER, JOEY]  FRIENDS    True   \n",
       "688                   [CHANDLER, ROSS, CHANDLER, ROSS]  FRIENDS    True   \n",
       "689                                             [ROSS]  FRIENDS    True   \n",
       "\n",
       "                                 sentiment_context_all  \\\n",
       "0    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
       "1    {'neg': 0.0, 'neu': 0.871, 'pos': 0.129, 'comp...   \n",
       "2    {'neg': 0.143, 'neu': 0.857, 'pos': 0.0, 'comp...   \n",
       "3    {'neg': 0.0, 'neu': 0.906, 'pos': 0.094, 'comp...   \n",
       "4    {'neg': 0.097, 'neu': 0.815, 'pos': 0.088, 'co...   \n",
       "..                                                 ...   \n",
       "685  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
       "686  {'neg': 0.062, 'neu': 0.751, 'pos': 0.187, 'co...   \n",
       "687  {'neg': 0.506, 'neu': 0.494, 'pos': 0.0, 'comp...   \n",
       "688  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
       "689  {'neg': 0.159, 'neu': 0.736, 'pos': 0.105, 'co...   \n",
       "\n",
       "                        sentiment_context_per_sentence  \\\n",
       "0    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...   \n",
       "1    [{'neg': 0.0, 'neu': 0.705, 'pos': 0.295, 'com...   \n",
       "2    [{'neg': 0.268, 'neu': 0.732, 'pos': 0.0, 'com...   \n",
       "3    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...   \n",
       "4    [{'neg': 0.202, 'neu': 0.439, 'pos': 0.36, 'co...   \n",
       "..                                                 ...   \n",
       "685  [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...   \n",
       "686  [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...   \n",
       "687  [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...   \n",
       "688  [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...   \n",
       "689  [{'neg': 0.159, 'neu': 0.736, 'pos': 0.105, 'c...   \n",
       "\n",
       "                                   sentiment_utterance  \n",
       "0    {'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'comp...  \n",
       "1    {'neg': 0.18, 'neu': 0.82, 'pos': 0.0, 'compou...  \n",
       "2    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "3    {'neg': 0.058, 'neu': 0.851, 'pos': 0.091, 'co...  \n",
       "4    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "..                                                 ...  \n",
       "685  {'neg': 0.102, 'neu': 0.898, 'pos': 0.0, 'comp...  \n",
       "686  {'neg': 0.0, 'neu': 0.858, 'pos': 0.142, 'comp...  \n",
       "687  {'neg': 0.0, 'neu': 0.763, 'pos': 0.237, 'comp...  \n",
       "688  {'neg': 0.0, 'neu': 0.781, 'pos': 0.219, 'comp...  \n",
       "689  {'neg': 0.0, 'neu': 0.527, 'pos': 0.473, 'comp...  \n",
       "\n",
       "[690 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: handle warning\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer # add pip install vaderSentiment to readme\n",
    "\n",
    "# Load VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Open the JSON file\n",
    "with open('data/sarcasm_data.json', 'r') as file:\n",
    "    # Load JSON data from the file\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Define a list of labels (columns) you want to extract\n",
    "labels = ['utterance', 'speaker', 'context', 'context_speakers', 'show', 'sarcasm']\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame(columns=labels)\n",
    "\n",
    "# Iterate over each key-value pair in the JSON data\n",
    "for key, value in json_data.items():\n",
    "    # Extract only the desired labels from the JSON data and add a new row to the DataFrame\n",
    "    row_data = {label: value[label] for label in labels}\n",
    "    \n",
    "    # Perform SA on the 'utterance' \n",
    "    sentiment_score_utterance = analyzer.polarity_scores(row_data['utterance'])\n",
    "    # Perform SA on all the context dialog  \n",
    "    sentiment_score_context_all = analyzer.polarity_scores(row_data['context'])\n",
    "\n",
    "    # List to store SA for every sentence in context dialog\n",
    "    sentiment_score_context_sentences = []\n",
    "    # Extract context dialog\n",
    "    context_sentences = row_data['context']\n",
    "\n",
    "    # Iterates over each sentence of the context dialog\n",
    "    for sentence in context_sentences:\n",
    "        # Perform SA\n",
    "        sentiment_score = analyzer.polarity_scores(sentence)\n",
    "        # Add sentence sentiment score to the list\n",
    "        sentiment_score_context_sentences.append(sentiment_score)\n",
    "\n",
    "        # If we want to match the sentence to the score:\n",
    "        #sentiment_score_context_sentences.append({'sentence': sentence, 'sentiment_score': sentiment_score})\n",
    "        \n",
    "    \n",
    "    # Add sentiment scores to the row data\n",
    "    row_data['sentiment_utterance'] = sentiment_score_utterance                     # Utterance\n",
    "    row_data['sentiment_context_all'] = sentiment_score_context_all                 # Context overall\n",
    "    row_data['sentiment_context_per_sentence'] = sentiment_score_context_sentences  # Context per sentence\n",
    "    \n",
    "    # Append the row to the DataFrame\n",
    "    df = df.append(row_data, ignore_index=True)\n",
    "\n",
    "# Visualize final dataframe df\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation format SA context and utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context all sequences: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "context per sequence: [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}]\n",
      "utterance: {'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'compound': 0.3612}\n"
     ]
    }
   ],
   "source": [
    "df_context = df['sentiment_context_all']\n",
    "\n",
    "print(\"context all sequences:\", df['sentiment_context_all'][0])\n",
    "df['sentiment_context_all'][0]\n",
    "print(\"context per sequence:\", df['sentiment_context_per_sentence'][0])\n",
    "print(\"utterance:\", df['sentiment_utterance'][0] )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
