{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\envs\\DL\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing and formating \"sentiment_features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Load the JSON file into a DataFrame\n",
    "file_path = 'data/sarcasm_data.json'\n",
    "df = pd.read_json(file_path).transpose()\n",
    "\n",
    "# Reset the index to turn the first element into a new column\n",
    "df = df.reset_index()\n",
    "\n",
    "# Define a function to apply sentiment analysis to a text\n",
    "def get_sentiment(text):\n",
    "    return analyzer.polarity_scores(text)\n",
    "\n",
    "# Apply sentiment analysis to the 'utterance' column\n",
    "df['sentiment_utterance'] = df['utterance'].apply(get_sentiment)\n",
    "\n",
    "# Apply sentiment analysis to the 'context' column\n",
    "df['sentiment_context_all'] = df['context'].apply(get_sentiment)\n",
    "\n",
    "# Apply sentiment analysis to each sentence in the 'context' column\n",
    "df['sentiment_context_per_sentence'] = df['context'].apply(lambda context: [get_sentiment(sentence) for sentence in context])\n",
    "\n",
    "df = df.transpose()\n",
    "df.to_json('sarcasm_data_valder.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_Valder():\n",
    "    df = pd.read_json('preprocessed_data/sarcasm_data_valder.json').transpose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U : Uterance sentiment\n",
    "# oC : Overall context sentiment\n",
    "# pC : Per sentence context sentiment\n",
    "\n",
    "# Add 1 with compound // Add 2 without it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments with pos, neu, neg and compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0                            [0.0, 0.783, 0.217, 0.3612]\n",
       " 1                [0.18, 0.8200000000000001, 0.0, -0.296]\n",
       " 2                                   [0.0, 1.0, 0.0, 0.0]\n",
       " 3             [0.058, 0.851, 0.091, 0.42150000000000004]\n",
       " 4                                   [0.0, 1.0, 0.0, 0.0]\n",
       "                              ...                        \n",
       " 685           [0.10200000000000001, 0.898, 0.0, -0.5106]\n",
       " 686    [0.0, 0.858, 0.14200000000000002, 0.3595000000...\n",
       " 687    [0.0, 0.763, 0.23700000000000002, 0.4215000000...\n",
       " 688             [0.0, 0.781, 0.219, 0.42150000000000004]\n",
       " 689             [0.0, 0.527, 0.47300000000000003, 0.659]\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg', 'utterance_neu', 'utterance_pos', 'utterance_compound'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_Valder()\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df['sentiment_utterance'].apply(lambda x: list(x.values()))\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "\n",
    "# Transpose the dataframe to get the orignal json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_valder_U1.json')\n",
    "\n",
    "df.iloc[-1], utterance_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments with pos, neu, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0                    [0.0, 0.783, 0.217]\n",
       " 1        [0.18, 0.8200000000000001, 0.0]\n",
       " 2                        [0.0, 1.0, 0.0]\n",
       " 3                  [0.058, 0.851, 0.091]\n",
       " 4                        [0.0, 1.0, 0.0]\n",
       "                      ...                \n",
       " 685    [0.10200000000000001, 0.898, 0.0]\n",
       " 686    [0.0, 0.858, 0.14200000000000002]\n",
       " 687    [0.0, 0.763, 0.23700000000000002]\n",
       " 688                  [0.0, 0.781, 0.219]\n",
       " 689    [0.0, 0.527, 0.47300000000000003]\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg', 'utterance_neu', 'utterance_pos'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_Valder()\n",
    "\n",
    "def remove_compound(dict):\n",
    "    return {key: value for key, value in dict.items() if key != 'compound'}\n",
    "\n",
    "# Apply the function to the 'sentiment_utterance' columns\n",
    "df['sentiment_utterance'] = df['sentiment_utterance'].apply(remove_compound)\n",
    "df['sentiment_features'] = df['sentiment_utterance'].apply(lambda x: list(x.values())) \n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_valder_U2.json')\n",
    "\n",
    "df.iloc[-1], utterance_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valder sentiment context overall + utterance with pos, neu, neg and compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        [0.0, 0.783, 0.217, 0.3612, 0.0, 1.0, 0.0, 0.0]\n",
       " 1      [0.18, 0.8200000000000001, 0.0, -0.296, 0.0, 0...\n",
       " 2      [0.0, 1.0, 0.0, 0.0, 0.14300000000000002, 0.85...\n",
       " 3      [0.058, 0.851, 0.091, 0.42150000000000004, 0.0...\n",
       " 4      [0.0, 1.0, 0.0, 0.0, 0.097, 0.8150000000000001...\n",
       "                              ...                        \n",
       " 685    [0.10200000000000001, 0.898, 0.0, -0.5106, 0.0...\n",
       " 686    [0.0, 0.858, 0.14200000000000002, 0.3595000000...\n",
       " 687    [0.0, 0.763, 0.23700000000000002, 0.4215000000...\n",
       " 688    [0.0, 0.781, 0.219, 0.42150000000000004, 0.0, ...\n",
       " 689    [0.0, 0.527, 0.47300000000000003, 0.659, 0.159...\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg',\n",
       "  'utterance_neu',\n",
       "  'utterance_pos',\n",
       "  'utterance_compound',\n",
       "  'context_neg',\n",
       "  'context_neu',\n",
       "  'context_pos',\n",
       "  'context_compound'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_Valder()\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "context_keys = ['context_' + key for key in df['sentiment_context_all'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "keys_list = utterance_keys + context_keys\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df.apply(lambda row: list(row['sentiment_utterance'].values()) + list(row['sentiment_context_all'].values()), axis=1)\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "# Save the DataFrame to a new JSON file\n",
    "df.to_json('sarcasm_data_valder_UoC1.json')\n",
    "\n",
    "df.iloc[-1], keys_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valder sentiment context overall + utterance with pos, neu, neg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0                     [0.0, 0.783, 0.217, 0.0, 1.0, 0.0]\n",
       " 1      [0.18, 0.8200000000000001, 0.0, 0.0, 0.871, 0....\n",
       " 2       [0.0, 1.0, 0.0, 0.14300000000000002, 0.857, 0.0]\n",
       " 3               [0.058, 0.851, 0.091, 0.0, 0.906, 0.094]\n",
       " 4      [0.0, 1.0, 0.0, 0.097, 0.8150000000000001, 0.088]\n",
       "                              ...                        \n",
       " 685     [0.10200000000000001, 0.898, 0.0, 0.0, 1.0, 0.0]\n",
       " 686    [0.0, 0.858, 0.14200000000000002, 0.062, 0.751...\n",
       " 687    [0.0, 0.763, 0.23700000000000002, 0.506, 0.494...\n",
       " 688                   [0.0, 0.781, 0.219, 0.0, 1.0, 0.0]\n",
       " 689    [0.0, 0.527, 0.47300000000000003, 0.159, 0.736...\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg',\n",
       "  'utterance_neu',\n",
       "  'utterance_pos',\n",
       "  'context_neg',\n",
       "  'context_neu',\n",
       "  'context_pos'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_Valder()\n",
    "\n",
    "def remove_compound(dict):\n",
    "    return {key: value for key, value in dict.items() if key != 'compound'}\n",
    "\n",
    "# Apply the function to the 'sentiment_utterance' and 'sentiment_context_all' columns\n",
    "df['sentiment_utterance'] = df['sentiment_utterance'].apply(remove_compound)\n",
    "df['sentiment_context_all'] = df['sentiment_context_all'].apply(remove_compound)\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "context_keys = ['context_' + key for key in df['sentiment_context_all'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "keys_list = utterance_keys + context_keys\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df['sentiment_utterance'].apply(lambda x: list(x.values())) + df['sentiment_context_all'].apply(lambda x: list(x.values()))\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_valder_UoC2.json')\n",
    "\n",
    "df.iloc[-1] , keys_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valder sentiment utterance + contex_per_sentence with pos, neu, neg and compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      [0.0, 0.783, 0.217, 0.3612, 0.0, 1.0, 0.0, 0.0...\n",
       " 1      [0.18, 0.8200000000000001, 0.0, -0.296, 0.0, 0...\n",
       " 2      [0.0, 1.0, 0.0, 0.0, 0.268, 0.732, 0.0, -0.296...\n",
       " 3      [0.058, 0.851, 0.091, 0.42150000000000004, 0.0...\n",
       " 4      [0.0, 1.0, 0.0, 0.0, 0.202, 0.439, 0.36, 0.421...\n",
       "                              ...                        \n",
       " 685    [0.10200000000000001, 0.898, 0.0, -0.5106, 0.0...\n",
       " 686    [0.0, 0.858, 0.14200000000000002, 0.3595000000...\n",
       " 687    [0.0, 0.763, 0.23700000000000002, 0.4215000000...\n",
       " 688    [0.0, 0.781, 0.219, 0.42150000000000004, 0.0, ...\n",
       " 689    [0.0, 0.527, 0.47300000000000003, 0.659, 0.159...\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg',\n",
       "  'utterance_neu',\n",
       "  'utterance_pos',\n",
       "  'utterance_compound',\n",
       "  'context_1_neg',\n",
       "  'context_1_neu',\n",
       "  'context_1_pos',\n",
       "  'context_1_compound',\n",
       "  'context_2_neg',\n",
       "  'context_2_neu',\n",
       "  'context_2_pos',\n",
       "  'context_2_compound',\n",
       "  'context_3_neg',\n",
       "  'context_3_neu',\n",
       "  'context_3_pos',\n",
       "  'context_3_compound'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to extract the 'neg', 'neu', 'pos', and 'compound' values from the first three dictionaries in a list\n",
    "def extract_values(sentences):\n",
    "    # Ensure the list has at least 3 dictionaries, padding if necessary\n",
    "    sentences.extend([{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound': 0.0}] * (3 - len(sentences)))\n",
    "    # Extract the values from the first 3 dictionaries\n",
    "    return [value for sentence in sentences[:3] for key, value in sentence.items()]\n",
    "\n",
    "df = get_data_Valder()\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "context_per_sentence_keys = [f\"context_{i}_{key}\" for i in range(1, 4) for key in ['neg', 'neu', 'pos', 'compound']]\n",
    "keys_list = utterance_keys + context_per_sentence_keys\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df.apply(lambda row: list(row['sentiment_utterance'].values()) + extract_values(row['sentiment_context_per_sentence']), axis=1)\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "# Save the DataFrame to a new JSON file\n",
    "df.to_json('sarcasm_data_valder_UpC1.json')\n",
    "\n",
    "df.iloc[-1], keys_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valder sentiment utterance + contex_per_sentence with pos, neu, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      [0.0, 0.783, 0.217, 0.0, 1.0, 0.0, 0.0, 1.0, 0...\n",
       " 1      [0.18, 0.8200000000000001, 0.0, 0.0, 0.705, 0....\n",
       " 2      [0.0, 1.0, 0.0, 0.268, 0.732, 0.0, 0.0, 1.0, 0...\n",
       " 3      [0.058, 0.851, 0.091, 0.0, 1.0, 0.0, 0.0, 0.58...\n",
       " 4      [0.0, 1.0, 0.0, 0.202, 0.439, 0.36, 0.356, 0.6...\n",
       "                              ...                        \n",
       " 685    [0.10200000000000001, 0.898, 0.0, 0.0, 1.0, 0....\n",
       " 686    [0.0, 0.858, 0.14200000000000002, 0.0, 1.0, 0....\n",
       " 687    [0.0, 0.763, 0.23700000000000002, 0.0, 1.0, 0....\n",
       " 688    [0.0, 0.781, 0.219, 0.0, 1.0, 0.0, 0.0, 1.0, 0...\n",
       " 689    [0.0, 0.527, 0.47300000000000003, 0.159, 0.736...\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg',\n",
       "  'utterance_neu',\n",
       "  'utterance_pos',\n",
       "  'context_1_neg',\n",
       "  'context_1_neu',\n",
       "  'context_1_pos',\n",
       "  'context_2_neg',\n",
       "  'context_2_neu',\n",
       "  'context_2_pos',\n",
       "  'context_3_neg',\n",
       "  'context_3_neu',\n",
       "  'context_3_pos'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to extract the 'neg', 'neu', 'pos', and 'compound' values from the first three dictionaries in a list\n",
    "def extract_values(sentences):\n",
    "    # Ensure the list has at least 3 dictionaries, padding if necessary\n",
    "    sentences.extend([{'neg': 0.0, 'neu': 0.0, 'pos': 0.0}] * (3 - len(sentences)))\n",
    "    # Extract the values from the first 3 dictionaries\n",
    "    return [value for sentence in sentences[:3] for key, value in sentence.items()]\n",
    "\n",
    "def remove_compound_1(dict):\n",
    "    return {key: value for key, value in dict.items() if key != 'compound'}\n",
    "def remove_compound_2(sentences):\n",
    "    return [{key: value for key, value in sentence.items() if key != 'compound'} for sentence in sentences]\n",
    "\n",
    "df = get_data_Valder()\n",
    "\n",
    "df['sentiment_utterance'] = df['sentiment_utterance'].apply(remove_compound_1)\n",
    "df['sentiment_context_per_sentence'] = df['sentiment_context_per_sentence'].apply(remove_compound_2)\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "context_per_sentence_keys = [f\"context_{i}_{key}\" for i in range(1, 4) for key in ['neg', 'neu', 'pos']]\n",
    "keys_list = utterance_keys + context_per_sentence_keys\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df.apply(lambda row: list(row['sentiment_utterance'].values()) + extract_values(row['sentiment_context_per_sentence']), axis=1)\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "# Save the DataFrame to a new JSON file\n",
    "df.to_json('sarcasm_data_valder_UpC2.json')\n",
    "\n",
    "df.iloc[-1], keys_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hartmann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\envs\\DL\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "def hartmann_sentiment(text):\n",
    "    text = classifier(text)\n",
    "    # Assuming 'text' is already defined and contains the necessary data\n",
    "    sentiments = [text[0][i]['score'] for i in range(6)]\n",
    "    sentiment = np.argmax(sentiments)\n",
    "    return sentiment\n",
    "\n",
    "# Load the JSON file into a DataFrame\n",
    "file_path = 'data/sarcasm_data.json'\n",
    "df = pd.read_json(file_path).transpose()\n",
    "\n",
    "# Reset the index to turn the first element into a new column\n",
    "df = df.reset_index()\n",
    "\n",
    "# Apply sentiment analysis to the 'utterance' column\n",
    "df['sentiment_utterance'] = df['utterance'].apply(hartmann_sentiment)\n",
    "\n",
    "# Apply sentiment analysis to the 'context' column\n",
    "df['sentiment_context_all'] = df['context'].apply(hartmann_sentiment)\n",
    "\n",
    "# Apply sentiment analysis to each sentence in the 'context' column\n",
    "df[\"sentiment_context_per_sentence\"] = df['context'].apply(lambda context: [hartmann_sentiment(sentence) for sentence in context])\n",
    "\n",
    "df = df.transpose()\n",
    "df.to_json('sarcasm_data_hartmann.json')\n",
    "\n",
    "# anger = 0, disgust = 1, fear = 2,  joy = 3, neutral = 4, sadness =  5, surprise = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_hartmann():\n",
    "    df = pd.read_json('preprocessed_data/sarcasm_data_hartmann.json').transpose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U : Uterance sentiment\n",
    "# oC : Overall context sentiment\n",
    "# pC : Per sentence context sentiment\n",
    "\n",
    "# anger = 0, disgust = 1, fear = 2,  joy = 3, neutral = 4, sadness =  5, surprise = 6 , missing_context = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      4\n",
       " 1      4\n",
       " 2      4\n",
       " 3      4\n",
       " 4      4\n",
       "       ..\n",
       " 685    0\n",
       " 686    1\n",
       " 687    4\n",
       " 688    1\n",
       " 689    3\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_hartmann()\n",
    "\n",
    "# Get the sentiment features\n",
    "df['sentiment_features'] = df[\"sentiment_utterance\"]\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_hartmann_U.json')\n",
    "\n",
    "df.iloc[-1], [\"utterance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments + context overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      [4, 4]\n",
       " 1      [4, 4]\n",
       " 2      [4, 4]\n",
       " 3      [4, 4]\n",
       " 4      [4, 2]\n",
       "         ...  \n",
       " 685    [0, 0]\n",
       " 686    [1, 0]\n",
       " 687    [4, 4]\n",
       " 688    [1, 4]\n",
       " 689    [3, 5]\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance', 'context'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_hartmann()\n",
    "\n",
    "# Get the sentiment features\n",
    "df['sentiment_features'] = [list(item) for item in zip(df[\"sentiment_utterance\"], df[\"sentiment_context_all\"])]\n",
    "\n",
    "# Get names of the columns\n",
    "keys_list = ['utterance'] +  ['context']\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_hartmann_UoC.json')\n",
    "\n",
    "df.iloc[-1], keys_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments + context per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       [4, 4, 5, -1]\n",
       " 1        [4, 4, 4, 4]\n",
       " 2        [4, 4, 4, 4]\n",
       " 3        [4, 4, 0, 4]\n",
       " 4        [4, 2, 1, 1]\n",
       "             ...      \n",
       " 685     [0, 0, 4, -1]\n",
       " 686      [1, 0, 4, 1]\n",
       " 687     [4, 4, 0, -1]\n",
       " 688      [1, 4, 4, 3]\n",
       " 689    [3, 5, -1, -1]\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance', 'context_1', 'context_2', 'context_3'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def take_first_three(contexts):\n",
    "    # If there are less than three contexts, pad the list with 'new_value'\n",
    "    while len(contexts) < 3:\n",
    "        contexts.append('-1')\n",
    "    # If there are more than three contexts, take the first three\n",
    "    return contexts[:3]\n",
    "\n",
    "df = get_data_hartmann()\n",
    "\n",
    "df['sentiment_context_per_sentence'] = df['sentiment_context_per_sentence'].apply(take_first_three)\n",
    "\n",
    "# Get the sentiment features\n",
    "df['sentiment_features'] = df.apply(lambda row: [row[\"sentiment_utterance\"]] + row[\"sentiment_context_per_sentence\"], axis=1)\n",
    "\n",
    "# Get names of the columns\n",
    "keys_list = ['utterance'] +  ['context_' + str(i) for i in range(1, 4)]\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_hartmann_UpC.json')\n",
    "\n",
    "df.iloc[-1], keys_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HateSpeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
