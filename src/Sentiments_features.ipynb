{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\envs\\DL\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing and formating \"sentiment_features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Load the JSON file into a DataFrame\n",
    "file_path = 'data/sarcasm_data.json'\n",
    "df = pd.read_json(file_path).transpose()\n",
    "\n",
    "# Reset the index to turn the first element into a new column\n",
    "df = df.reset_index()\n",
    "\n",
    "# Define a function to apply sentiment analysis to a text\n",
    "def get_sentiment(text):\n",
    "    return analyzer.polarity_scores(text)\n",
    "\n",
    "# Apply sentiment analysis to the 'utterance' column\n",
    "df['sentiment_utterance'] = df['utterance'].apply(get_sentiment)\n",
    "\n",
    "# Apply sentiment analysis to the 'context' column\n",
    "df['sentiment_context_all'] = df['context'].apply(get_sentiment)\n",
    "\n",
    "# Apply sentiment analysis to each sentence in the 'context' column\n",
    "df['sentiment_context_per_sentence'] = df['context'].apply(lambda context: [get_sentiment(sentence) for sentence in context])\n",
    "\n",
    "df = df.transpose()\n",
    "df.to_json('sarcasm_data_vader.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_Valder():\n",
    "    df = pd.read_json('../preprocessed_data/sarcasm_data_vader.json').transpose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U : Uterance sentiment\n",
    "# oC : Overall context sentiment\n",
    "# pC : Per sentence context sentiment\n",
    "\n",
    "# Add 1 with compound // Add 2 without it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments with pos, neu, neg and compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0                            [0.0, 0.783, 0.217, 0.3612]\n",
       " 1                [0.18, 0.8200000000000001, 0.0, -0.296]\n",
       " 2                                   [0.0, 1.0, 0.0, 0.0]\n",
       " 3             [0.058, 0.851, 0.091, 0.42150000000000004]\n",
       " 4                                   [0.0, 1.0, 0.0, 0.0]\n",
       "                              ...                        \n",
       " 685           [0.10200000000000001, 0.898, 0.0, -0.5106]\n",
       " 686    [0.0, 0.858, 0.14200000000000002, 0.3595000000...\n",
       " 687    [0.0, 0.763, 0.23700000000000002, 0.4215000000...\n",
       " 688             [0.0, 0.781, 0.219, 0.42150000000000004]\n",
       " 689             [0.0, 0.527, 0.47300000000000003, 0.659]\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg', 'utterance_neu', 'utterance_pos', 'utterance_compound'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_Valder()\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df['sentiment_utterance'].apply(lambda x: list(x.values()))\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "\n",
    "# Transpose the dataframe to get the orignal json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_vader1_U.json')\n",
    "\n",
    "df.iloc[-1], utterance_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments with pos, neu, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0                    [0.0, 0.783, 0.217]\n",
       " 1        [0.18, 0.8200000000000001, 0.0]\n",
       " 2                        [0.0, 1.0, 0.0]\n",
       " 3                  [0.058, 0.851, 0.091]\n",
       " 4                        [0.0, 1.0, 0.0]\n",
       "                      ...                \n",
       " 685    [0.10200000000000001, 0.898, 0.0]\n",
       " 686    [0.0, 0.858, 0.14200000000000002]\n",
       " 687    [0.0, 0.763, 0.23700000000000002]\n",
       " 688                  [0.0, 0.781, 0.219]\n",
       " 689    [0.0, 0.527, 0.47300000000000003]\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg', 'utterance_neu', 'utterance_pos'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_Valder()\n",
    "\n",
    "def remove_compound(dict):\n",
    "    return {key: value for key, value in dict.items() if key != 'compound'}\n",
    "\n",
    "# Apply the function to the 'sentiment_utterance' columns\n",
    "df['sentiment_utterance'] = df['sentiment_utterance'].apply(remove_compound)\n",
    "df['sentiment_features'] = df['sentiment_utterance'].apply(lambda x: list(x.values())) \n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_vader2_U.json')\n",
    "\n",
    "df.iloc[-1], utterance_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valder sentiment context overall + utterance with pos, neu, neg and compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        [0.0, 0.783, 0.217, 0.3612, 0.0, 1.0, 0.0, 0.0]\n",
       " 1      [0.18, 0.8200000000000001, 0.0, -0.296, 0.0, 0...\n",
       " 2      [0.0, 1.0, 0.0, 0.0, 0.14300000000000002, 0.85...\n",
       " 3      [0.058, 0.851, 0.091, 0.42150000000000004, 0.0...\n",
       " 4      [0.0, 1.0, 0.0, 0.0, 0.097, 0.8150000000000001...\n",
       "                              ...                        \n",
       " 685    [0.10200000000000001, 0.898, 0.0, -0.5106, 0.0...\n",
       " 686    [0.0, 0.858, 0.14200000000000002, 0.3595000000...\n",
       " 687    [0.0, 0.763, 0.23700000000000002, 0.4215000000...\n",
       " 688    [0.0, 0.781, 0.219, 0.42150000000000004, 0.0, ...\n",
       " 689    [0.0, 0.527, 0.47300000000000003, 0.659, 0.159...\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg',\n",
       "  'utterance_neu',\n",
       "  'utterance_pos',\n",
       "  'utterance_compound',\n",
       "  'context_neg',\n",
       "  'context_neu',\n",
       "  'context_pos',\n",
       "  'context_compound'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_Valder()\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "context_keys = ['context_' + key for key in df['sentiment_context_all'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "keys_list = utterance_keys + context_keys\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df.apply(lambda row: list(row['sentiment_utterance'].values()) + list(row['sentiment_context_all'].values()), axis=1)\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "# Save the DataFrame to a new JSON file\n",
    "df.to_json('sarcasm_data_vader1_UoC.json')\n",
    "\n",
    "df.iloc[-1], keys_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valder sentiment context overall + utterance with pos, neu, neg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0                     [0.0, 0.783, 0.217, 0.0, 1.0, 0.0]\n",
       " 1      [0.18, 0.8200000000000001, 0.0, 0.0, 0.871, 0....\n",
       " 2       [0.0, 1.0, 0.0, 0.14300000000000002, 0.857, 0.0]\n",
       " 3               [0.058, 0.851, 0.091, 0.0, 0.906, 0.094]\n",
       " 4      [0.0, 1.0, 0.0, 0.097, 0.8150000000000001, 0.088]\n",
       "                              ...                        \n",
       " 685     [0.10200000000000001, 0.898, 0.0, 0.0, 1.0, 0.0]\n",
       " 686    [0.0, 0.858, 0.14200000000000002, 0.062, 0.751...\n",
       " 687    [0.0, 0.763, 0.23700000000000002, 0.506, 0.494...\n",
       " 688                   [0.0, 0.781, 0.219, 0.0, 1.0, 0.0]\n",
       " 689    [0.0, 0.527, 0.47300000000000003, 0.159, 0.736...\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg',\n",
       "  'utterance_neu',\n",
       "  'utterance_pos',\n",
       "  'context_neg',\n",
       "  'context_neu',\n",
       "  'context_pos'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_Valder()\n",
    "\n",
    "def remove_compound(dict):\n",
    "    return {key: value for key, value in dict.items() if key != 'compound'}\n",
    "\n",
    "# Apply the function to the 'sentiment_utterance' and 'sentiment_context_all' columns\n",
    "df['sentiment_utterance'] = df['sentiment_utterance'].apply(remove_compound)\n",
    "df['sentiment_context_all'] = df['sentiment_context_all'].apply(remove_compound)\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "context_keys = ['context_' + key for key in df['sentiment_context_all'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "keys_list = utterance_keys + context_keys\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df['sentiment_utterance'].apply(lambda x: list(x.values())) + df['sentiment_context_all'].apply(lambda x: list(x.values()))\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_vader2_UoC.json')\n",
    "\n",
    "df.iloc[-1] , keys_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valder sentiment utterance + contex_per_sentence with pos, neu, neg and compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      [0.0, 0.783, 0.217, 0.3612, 0.0, 1.0, 0.0, 0.0...\n",
       " 1      [0.18, 0.8200000000000001, 0.0, -0.296, 0.0, 0...\n",
       " 2      [0.0, 1.0, 0.0, 0.0, 0.268, 0.732, 0.0, -0.296...\n",
       " 3      [0.058, 0.851, 0.091, 0.42150000000000004, 0.0...\n",
       " 4      [0.0, 1.0, 0.0, 0.0, 0.202, 0.439, 0.36, 0.421...\n",
       "                              ...                        \n",
       " 685    [0.10200000000000001, 0.898, 0.0, -0.5106, 0.0...\n",
       " 686    [0.0, 0.858, 0.14200000000000002, 0.3595000000...\n",
       " 687    [0.0, 0.763, 0.23700000000000002, 0.4215000000...\n",
       " 688    [0.0, 0.781, 0.219, 0.42150000000000004, 0.0, ...\n",
       " 689    [0.0, 0.527, 0.47300000000000003, 0.659, 0.159...\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg',\n",
       "  'utterance_neu',\n",
       "  'utterance_pos',\n",
       "  'utterance_compound',\n",
       "  'context_1_neg',\n",
       "  'context_1_neu',\n",
       "  'context_1_pos',\n",
       "  'context_1_compound',\n",
       "  'context_2_neg',\n",
       "  'context_2_neu',\n",
       "  'context_2_pos',\n",
       "  'context_2_compound',\n",
       "  'context_3_neg',\n",
       "  'context_3_neu',\n",
       "  'context_3_pos',\n",
       "  'context_3_compound'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to extract the 'neg', 'neu', 'pos', and 'compound' values from the first three dictionaries in a list\n",
    "def extract_values(sentences):\n",
    "    # Ensure the list has at least 3 dictionaries, padding if necessary\n",
    "    sentences.extend([{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound': 0.0}] * (3 - len(sentences)))\n",
    "    # Extract the values from the first 3 dictionaries\n",
    "    return [value for sentence in sentences[:3] for key, value in sentence.items()]\n",
    "\n",
    "df = get_data_Valder()\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "context_per_sentence_keys = [f\"context_{i}_{key}\" for i in range(1, 4) for key in ['neg', 'neu', 'pos', 'compound']]\n",
    "keys_list = utterance_keys + context_per_sentence_keys\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df.apply(lambda row: list(row['sentiment_utterance'].values()) + extract_values(row['sentiment_context_per_sentence']), axis=1)\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "# Save the DataFrame to a new JSON file\n",
    "df.to_json('sarcasm_data_vader1_UpC.json')\n",
    "\n",
    "df.iloc[-1], keys_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valder sentiment utterance + contex_per_sentence with pos, neu, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      [0.0, 0.783, 0.217, 0.0, 1.0, 0.0, 0.0, 1.0, 0...\n",
       " 1      [0.18, 0.8200000000000001, 0.0, 0.0, 0.705, 0....\n",
       " 2      [0.0, 1.0, 0.0, 0.268, 0.732, 0.0, 0.0, 1.0, 0...\n",
       " 3      [0.058, 0.851, 0.091, 0.0, 1.0, 0.0, 0.0, 0.58...\n",
       " 4      [0.0, 1.0, 0.0, 0.202, 0.439, 0.36, 0.356, 0.6...\n",
       "                              ...                        \n",
       " 685    [0.10200000000000001, 0.898, 0.0, 0.0, 1.0, 0....\n",
       " 686    [0.0, 0.858, 0.14200000000000002, 0.0, 1.0, 0....\n",
       " 687    [0.0, 0.763, 0.23700000000000002, 0.0, 1.0, 0....\n",
       " 688    [0.0, 0.781, 0.219, 0.0, 1.0, 0.0, 0.0, 1.0, 0...\n",
       " 689    [0.0, 0.527, 0.47300000000000003, 0.159, 0.736...\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg',\n",
       "  'utterance_neu',\n",
       "  'utterance_pos',\n",
       "  'context_1_neg',\n",
       "  'context_1_neu',\n",
       "  'context_1_pos',\n",
       "  'context_2_neg',\n",
       "  'context_2_neu',\n",
       "  'context_2_pos',\n",
       "  'context_3_neg',\n",
       "  'context_3_neu',\n",
       "  'context_3_pos'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to extract the 'neg', 'neu', 'pos', and 'compound' values from the first three dictionaries in a list\n",
    "def extract_values(sentences):\n",
    "    # Ensure the list has at least 3 dictionaries, padding if necessary\n",
    "    sentences.extend([{'neg': 0.0, 'neu': 0.0, 'pos': 0.0}] * (3 - len(sentences)))\n",
    "    # Extract the values from the first 3 dictionaries\n",
    "    return [value for sentence in sentences[:3] for key, value in sentence.items()]\n",
    "\n",
    "def remove_compound_1(dict):\n",
    "    return {key: value for key, value in dict.items() if key != 'compound'}\n",
    "def remove_compound_2(sentences):\n",
    "    return [{key: value for key, value in sentence.items() if key != 'compound'} for sentence in sentences]\n",
    "\n",
    "df = get_data_Valder()\n",
    "\n",
    "df['sentiment_utterance'] = df['sentiment_utterance'].apply(remove_compound_1)\n",
    "df['sentiment_context_per_sentence'] = df['sentiment_context_per_sentence'].apply(remove_compound_2)\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "context_per_sentence_keys = [f\"context_{i}_{key}\" for i in range(1, 4) for key in ['neg', 'neu', 'pos']]\n",
    "keys_list = utterance_keys + context_per_sentence_keys\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df.apply(lambda row: list(row['sentiment_utterance'].values()) + extract_values(row['sentiment_context_per_sentence']), axis=1)\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "# Save the DataFrame to a new JSON file\n",
    "df.to_json('sarcasm_data_vader2_UpC.json')\n",
    "\n",
    "df.iloc[-1], keys_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hartmann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\envs\\DL\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "def hartmann_sentiment(text):\n",
    "    return classifier(text)[0]\n",
    "\n",
    "# Load the JSON file into a DataFrame\n",
    "file_path = 'data/sarcasm_data.json'\n",
    "df = pd.read_json(file_path).transpose()\n",
    "\n",
    "# Reset the index to turn the first element into a new column\n",
    "df = df.reset_index()\n",
    "\n",
    "# Apply sentiment analysis to the 'utterance' column\n",
    "df['sentiment_utterance'] = df['utterance'].apply(hartmann_sentiment)\n",
    "\n",
    "# Apply sentiment analysis to the 'context' column\n",
    "df['sentiment_context_all'] = df['context'].apply(hartmann_sentiment)\n",
    "\n",
    "# Apply sentiment analysis to each sentence in the 'context' column\n",
    "df[\"sentiment_context_per_sentence\"] = df['context'].apply(lambda context: [hartmann_sentiment(sentence) for sentence in context])\n",
    "\n",
    "df = df.transpose()\n",
    "df.to_json('sarcasm_data_hartmann.json')\n",
    "\n",
    "# anger = 0, disgust = 1, fear = 2,  joy = 3, neutral = 4, sadness =  5, surprise = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_hartmann():\n",
    "    df = pd.read_json('..//preprocessed_data/sarcasm_data_hartmann.json').transpose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U : Uterance sentiment\n",
    "# oC : Overall context sentiment\n",
    "# pC : Per sentence context sentiment\n",
    "\n",
    "# anger = 0, disgust = 1, fear = 2,  joy = 3, neutral = 4, sadness =  5, surprise = 6 , missing_context = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments (MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      4\n",
       " 1      6\n",
       " 2      4\n",
       " 3      6\n",
       " 4      4\n",
       "       ..\n",
       " 685    0\n",
       " 686    1\n",
       " 687    4\n",
       " 688    1\n",
       " 689    3\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance'],\n",
       " {0: 'anger',\n",
       "  1: 'disgust',\n",
       "  2: 'fear',\n",
       "  3: 'joy',\n",
       "  4: 'neutral',\n",
       "  5: 'sadness',\n",
       "  6: 'surprise'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_hartmann()\n",
    "\n",
    "# Create a mapping from index number to sentiment label\n",
    "index_to_label = {i: d['label'] for i, d in enumerate(df['sentiment_utterance'].iloc[0])}\n",
    "\n",
    "# Get the sentiment features\n",
    "df['sentiment_features'] = df['sentiment_utterance'].apply(lambda x: np.argmax([d['score'] for d in x]))\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_hartmann_max_U.json')\n",
    "\n",
    "df.iloc[-1], [\"utterance\"] , index_to_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments + context overall (MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      [4, 4]\n",
       " 1      [6, 4]\n",
       " 2      [4, 4]\n",
       " 3      [6, 6]\n",
       " 4      [4, 2]\n",
       "         ...  \n",
       " 685    [0, 0]\n",
       " 686    [1, 6]\n",
       " 687    [4, 4]\n",
       " 688    [1, 6]\n",
       " 689    [3, 5]\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance', 'context'],\n",
       " {0: 'anger',\n",
       "  1: 'disgust',\n",
       "  2: 'fear',\n",
       "  3: 'joy',\n",
       "  4: 'neutral',\n",
       "  5: 'sadness',\n",
       "  6: 'surprise'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_hartmann()\n",
    "\n",
    "# Create a mapping from index number to sentiment label\n",
    "index_to_label = {i: d['label'] for i, d in enumerate(df['sentiment_utterance'].iloc[0])}\n",
    "\n",
    "# Get the argmax sentiment score\n",
    "df['sentiment_utterance'] = df['sentiment_utterance'].apply(lambda x: np.argmax([d['score'] for d in x]))\n",
    "df[\"sentiment_context_all\"] = df[\"sentiment_context_all\"].apply(lambda x: np.argmax([d['score'] for d in x]))\n",
    "\n",
    "# Get the sentiment features\n",
    "df['sentiment_features'] = [list(item) for item in zip(df[\"sentiment_utterance\"], df[\"sentiment_context_all\"])]\n",
    "\n",
    "# Get names of the columns\n",
    "keys_list = ['utterance'] +  ['context']\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_hartmann_max_UoC.json')\n",
    "\n",
    "df.iloc[-1], keys_list , index_to_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments + context per sentence (MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      4\n",
      "1      6\n",
      "2      4\n",
      "3      6\n",
      "4      4\n",
      "      ..\n",
      "685    0\n",
      "686    1\n",
      "687    4\n",
      "688    1\n",
      "689    3\n",
      "Name: sentiment_utterance, Length: 690, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0       [4, 4, 5, -1]\n",
       " 1        [6, 4, 4, 4]\n",
       " 2        [4, 4, 4, 4]\n",
       " 3        [6, 6, 0, 4]\n",
       " 4        [4, 2, 1, 1]\n",
       "             ...      \n",
       " 685     [0, 0, 4, -1]\n",
       " 686      [1, 6, 6, 1]\n",
       " 687     [4, 4, 0, -1]\n",
       " 688      [1, 6, 4, 3]\n",
       " 689    [3, 5, -1, -1]\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance', 'context_1', 'context_2', 'context_3'],\n",
       " {0: 'anger',\n",
       "  1: 'disgust',\n",
       "  2: 'fear',\n",
       "  3: 'joy',\n",
       "  4: 'neutral',\n",
       "  5: 'sadness',\n",
       "  6: 'surprise',\n",
       "  -1: 'missing_context'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def take_first_three(contexts):\n",
    "    # If there are less than three contexts, pad the list with 'new_value'\n",
    "    while len(contexts) < 3:\n",
    "        contexts.append('-1')\n",
    "    # If there are more than three contexts, take the first three\n",
    "    return contexts[:3]\n",
    "def flatten_list_of_dicts(list_of_lists):\n",
    "    return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "df = get_data_hartmann()\n",
    "\n",
    "# Create a mapping from index number to sentiment label\n",
    "index_to_label = {i: d['label'] for i, d in enumerate(df['sentiment_utterance'].iloc[0])}\n",
    "index_to_label = {**index_to_label, -1: 'missing_context'}\n",
    "\n",
    "# Get the argmax sentiment score\n",
    "df['sentiment_utterance'] = df['sentiment_utterance'].apply(lambda x: np.argmax([d['score'] for d in x]))\n",
    "df[\"sentiment_context_per_sentence\"] = df[\"sentiment_context_per_sentence\"].apply(lambda x: [np.argmax([d['score'] for d in sublist]) for sublist in x])\n",
    "\n",
    "df['sentiment_context_per_sentence'] = df['sentiment_context_per_sentence'].apply(take_first_three)\n",
    "\n",
    "print(df['sentiment_utterance'])\n",
    "# Get the sentiment features\n",
    "df['sentiment_features'] = df.apply(lambda row: [row[\"sentiment_utterance\"]] + row[\"sentiment_context_per_sentence\"], axis=1)\n",
    "\n",
    "# Get names of the columns\n",
    "keys_list = ['utterance'] +  ['context_' + str(i) for i in range(1, 4)]\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_hartmann_max_UpC.json')\n",
    "\n",
    "df.iloc[-1], keys_list , index_to_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      [0.010123579800000001, 0.0143101504, 0.0011973...\n",
       " 1      [0.0273885094, 0.045210629700000005, 0.0265790...\n",
       " 2      [0.0048839869, 0.0049315374, 0.0015044714, 0.0...\n",
       " 3      [0.0979550406, 0.0185232982, 0.1187259331, 0.0...\n",
       " 4      [0.0098890308, 0.0246547051, 0.0029980363, 0.0...\n",
       "                              ...                        \n",
       " 685    [0.759996593, 0.1669357866, 0.0182649642, 0.00...\n",
       " 686    [0.340244025, 0.4619074166, 0.0146603724, 0.00...\n",
       " 687    [0.0086229192, 0.0097058332, 0.0121506732, 0.0...\n",
       " 688    [0.0083397916, 0.7863316536, 0.004822876800000...\n",
       " 689    [0.005968420800000001, 0.0016014389, 0.0021068...\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_anger',\n",
       "  'utterance_disgust',\n",
       "  'utterance_fear',\n",
       "  'utterance_joy',\n",
       "  'utterance_neutral',\n",
       "  'utterance_sadness',\n",
       "  'utterance_surprise'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_hartmann()\n",
    "\n",
    "# Get the sentiment features\n",
    "df['sentiment_features'] = df['sentiment_utterance'].apply(lambda x: [d['score'] for d in x])\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "labels = ['utterance_' + d['label'] for d in df['sentiment_utterance'].iloc[0]]\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_hartmann_U.json')\n",
    "\n",
    "df.iloc[-1], labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments + context overall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.010123579800000001,\n",
       "  0.0143101504,\n",
       "  0.0011973934,\n",
       "  0.057147428400000005,\n",
       "  0.9046183228,\n",
       "  0.0029129912000000003,\n",
       "  0.0096901413,\n",
       "  0.0301044136,\n",
       "  0.0456504636,\n",
       "  0.061435729300000005,\n",
       "  0.0034190910000000004,\n",
       "  0.5549920797,\n",
       "  0.0093617234,\n",
       "  0.2950364351],\n",
       " ['utterance_anger',\n",
       "  'utterance_disgust',\n",
       "  'utterance_fear',\n",
       "  'utterance_joy',\n",
       "  'utterance_neutral',\n",
       "  'utterance_sadness',\n",
       "  'utterance_surprise',\n",
       "  'context_anger',\n",
       "  'context_disgust',\n",
       "  'context_fear',\n",
       "  'context_joy',\n",
       "  'context_neutral',\n",
       "  'context_sadness',\n",
       "  'context_surprise'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_hartmann()\n",
    "\n",
    "# Get the sentiment features\n",
    "df['sentiment_features'] = df['sentiment_utterance'].apply(lambda x: [d['score'] for d in x]) + df['sentiment_context_all'].apply(lambda x: [d['score'] for d in x])\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "labels_utter = ['utterance_' + d['label'] for d in df['sentiment_utterance'].iloc[0]]\n",
    "labels_context = ['context_' + d['label'] for d in df['sentiment_context_all'].iloc[0]]\n",
    "labels = labels_utter + labels_context\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_hartmann_UoC.json')\n",
    "\n",
    "df.iloc[-1][0], labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments + context per sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.010123579800000001, 0.0143101504, 0.0011973934, 0.057147428400000005, 0.9046183228, 0.0029129912000000003, 0.0096901413, 0.0301044136, 0.0456504636, 0.061435729300000005, 0.0034190910000000004, 0.5549920797, 0.0093617234, 0.2950364351, 0.0439296663, 0.0407607555, 0.032509129500000004, 0.0059855198, 0.2351579964, 0.5660635829, 0.07559338210000001, 0, 0, 0, 0, 0, 0, 0] \n",
      " ['utterance_anger', 'utterance_disgust', 'utterance_fear', 'utterance_joy', 'utterance_neutral', 'utterance_sadness', 'utterance_surprise', 'context_1_utterance_anger', 'context_1_utterance_disgust', 'context_1_utterance_fear', 'context_1_utterance_joy', 'context_1_utterance_neutral', 'context_1_utterance_sadness', 'context_1_utterance_surprise', 'context_2_utterance_anger', 'context_2_utterance_disgust', 'context_2_utterance_fear', 'context_2_utterance_joy', 'context_2_utterance_neutral', 'context_2_utterance_sadness', 'context_2_utterance_surprise', 'context_3_utterance_anger', 'context_3_utterance_disgust', 'context_3_utterance_fear', 'context_3_utterance_joy', 'context_3_utterance_neutral', 'context_3_utterance_sadness', 'context_3_utterance_surprise']\n",
      "Length of a row:  28 Length of labels 28\n"
     ]
    }
   ],
   "source": [
    "# Padding function to ensure at least 21 (7*3) scores (context per sentence) per row\n",
    "def pad_scores(scores, target_length=7*3, padding_value=0):\n",
    "    return scores + [padding_value] * (target_length - len(scores))\n",
    "\n",
    "df = get_data_hartmann()\n",
    "labels_utter = ['utterance_' + d['label'] for d in df['sentiment_utterance'].iloc[0]]\n",
    "labels_context = [f\"context_{i}_{key}\" for i in range(1, 4) for key in labels_utter]\n",
    "labels = labels_utter + labels_context\n",
    "\n",
    "\n",
    "\n",
    "# Utterance sentiment\n",
    "df['sentiment_utterance'] = df['sentiment_utterance'].apply(lambda x: [d['score']for d in x]) \n",
    "# Get only the first three contexts per row\n",
    "df[\"sentiment_context_per_sentence\"] = df[\"sentiment_context_per_sentence\"].apply(lambda x: [d['score'] for sublist in x[:3] for d in sublist])\n",
    "# Apply padding if there are fewer than 21 values\n",
    "df['sentiment_context_per_sentence'] = df['sentiment_context_per_sentence'].apply(lambda x: pad_scores(x))\n",
    "\n",
    "\n",
    "# Get the sentiment features\n",
    "df['sentiment_features'] = df.apply(lambda row: row[\"sentiment_utterance\"] + row[\"sentiment_context_per_sentence\"], axis=1)\n",
    "\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_hartmann_UpC.json')\n",
    "\n",
    "print(df.iloc[-1][0],\"\\n\",labels)\n",
    "print(\"Length of a row: \",len(df.iloc[-1][0]),\"Length of labels\",len(labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HateSpeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
