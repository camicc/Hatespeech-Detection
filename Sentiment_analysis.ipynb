{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Load the JSON file into a DataFrame\n",
    "file_path = 'data/sarcasm_data.json'\n",
    "df = pd.read_json(file_path).transpose()\n",
    "\n",
    "# Reset the index to turn the first element into a new column\n",
    "df = df.reset_index()\n",
    "\n",
    "# Define a function to apply sentiment analysis to a text\n",
    "def get_sentiment(text):\n",
    "    return analyzer.polarity_scores(text)\n",
    "\n",
    "# Apply sentiment analysis to the 'utterance' column\n",
    "df['sentiment_utterance'] = df['utterance'].apply(get_sentiment)\n",
    "\n",
    "# Apply sentiment analysis to the 'context' column\n",
    "df['sentiment_context_all'] = df['context'].apply(get_sentiment)\n",
    "\n",
    "# Apply sentiment analysis to each sentence in the 'context' column\n",
    "df['sentiment_context_per_sentence'] = df['context'].apply(lambda context: [get_sentiment(sentence) for sentence in context])\n",
    "\n",
    "# Visualize the DataFrame\n",
    "df\n",
    "\n",
    "if False:\n",
    "    # Transform the 'sentiment_utterance' column into arrays of scores\n",
    "    df['sentiment_utterance'] = df['sentiment_utterance'].apply(lambda x: list(x.values()))\n",
    "\n",
    "    # add the context scores to the sentiment_utterance column\n",
    "    df['sentiment_utterance'] = df['sentiment_utterance'] + df['sentiment_context_all'].apply(lambda x: list(x.values()))\n",
    "\n",
    "    # Transpose the dataframe to get the orignal json format\n",
    "    df = df.transpose()\n",
    "\n",
    "    # Save the DataFrame to a new JSON file\n",
    "    df.to_json('data/sarcasm_data_sentiment.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation format SA context and utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context all sequences: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "context per sequence: [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}]\n",
      "utterance: {'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'compound': 0.3612}\n"
     ]
    }
   ],
   "source": [
    "df_context = df['sentiment_context_all']\n",
    "\n",
    "print(\"context all sequences:\", df['sentiment_context_all'][0])\n",
    "df['sentiment_context_all'][0]\n",
    "print(\"context per sequence:\", df['sentiment_context_per_sentence'][0])\n",
    "print(\"utterance:\", df['sentiment_utterance'][0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data with overal context sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts sarcasm True to 1 and False to 0\n",
    "y = df['sarcasm'].astype(int).tolist()\n",
    "\n",
    "context_all = df[\"sentiment_context_all\"]\n",
    "context_sentences = df[\"sentiment_context_per_sentence\"]\n",
    "utterance = df[\"sentiment_utterance\"]\n",
    "\n",
    "# Extracting 'neg', 'neu', and 'pos' per sentence and add index to keep context \n",
    "X = np.array([ [context_all[i]['neg'], context_all[i]['neu'], context_all[i]['pos'], utterance[i]['neg'], utterance[i]['neu'], utterance[i]['pos']] for i in range(context_all.shape[0]) ])\n",
    "\n",
    "X_df = pd.DataFrame(X, columns=['context_neg', 'context_neu', 'context_pos', 'utterance_neg', 'utterance_neu', 'utterance_pos'])\n",
    "\n",
    "# Split the dataset into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_neg</th>\n",
       "      <th>context_neu</th>\n",
       "      <th>context_pos</th>\n",
       "      <th>utterance_neg</th>\n",
       "      <th>utterance_neu</th>\n",
       "      <th>utterance_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.143</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.097</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0.062</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0.506</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>0.159</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     context_neg  context_neu  context_pos  utterance_neg  utterance_neu  \\\n",
       "0          0.000        1.000        0.000          0.000          0.783   \n",
       "1          0.000        0.871        0.129          0.180          0.820   \n",
       "2          0.143        0.857        0.000          0.000          1.000   \n",
       "3          0.000        0.906        0.094          0.058          0.851   \n",
       "4          0.097        0.815        0.088          0.000          1.000   \n",
       "..           ...          ...          ...            ...            ...   \n",
       "685        0.000        1.000        0.000          0.102          0.898   \n",
       "686        0.062        0.751        0.187          0.000          0.858   \n",
       "687        0.506        0.494        0.000          0.000          0.763   \n",
       "688        0.000        1.000        0.000          0.000          0.781   \n",
       "689        0.159        0.736        0.105          0.000          0.527   \n",
       "\n",
       "     utterance_pos  \n",
       "0            0.217  \n",
       "1            0.000  \n",
       "2            0.000  \n",
       "3            0.091  \n",
       "4            0.000  \n",
       "..             ...  \n",
       "685          0.000  \n",
       "686          0.142  \n",
       "687          0.237  \n",
       "688          0.219  \n",
       "689          0.473  \n",
       "\n",
       "[690 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sentence specific context sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the y and x match: True\n"
     ]
    }
   ],
   "source": [
    "# Extracted keys for the floats\n",
    "keys = ['neg', 'neu', 'pos']\n",
    "\n",
    "# Initialize a list to hold the resulting arrays\n",
    "X_sentences = []\n",
    "\n",
    "# Update sarcasm labels\n",
    "y_sentences = []\n",
    "\n",
    "# Process each array (list of dictionaries)\n",
    "for idx, sentences in enumerate(context_sentences):\n",
    "    for entry in sentences:\n",
    "        # Extract values for each key and concatenate with the index\n",
    "        values = [entry.get(key, 0) for key in keys]\n",
    "\n",
    "        # Create entries like so: index, negative score, neutral score, positive score \n",
    "        X_sentences.append([idx] + values + [utterance[idx]['neg'] , utterance[idx]['neu'] , utterance[idx]['pos']])\n",
    "\n",
    "        # Update labels\n",
    "        y_sentences.append(y[idx])\n",
    "    \n",
    "print(\"The size of the y and x match:\",len(X_sentences)==len(y_sentences))\n",
    "\n",
    "# Split the dataset into 80% training and 20% testing\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(X_sentences, y_sentences, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance idx</th>\n",
       "      <th>sentence_neg</th>\n",
       "      <th>sentence_neu</th>\n",
       "      <th>sentence_pos</th>\n",
       "      <th>utterance_neg</th>\n",
       "      <th>utterance_neu</th>\n",
       "      <th>utterance_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>688</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>688</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>688</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>688</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>689</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2261 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      utterance idx  sentence_neg  sentence_neu  sentence_pos  utterance_neg  \\\n",
       "0                 0         0.000         1.000         0.000           0.00   \n",
       "1                 0         0.000         1.000         0.000           0.00   \n",
       "2                 1         0.000         0.705         0.295           0.18   \n",
       "3                 1         0.000         0.303         0.697           0.18   \n",
       "4                 1         0.000         0.732         0.268           0.18   \n",
       "...             ...           ...           ...           ...            ...   \n",
       "2256            688         0.000         1.000         0.000           0.00   \n",
       "2257            688         0.000         1.000         0.000           0.00   \n",
       "2258            688         0.000         0.000         1.000           0.00   \n",
       "2259            688         0.000         1.000         0.000           0.00   \n",
       "2260            689         0.159         0.736         0.105           0.00   \n",
       "\n",
       "      utterance_neu  utterance_pos  \n",
       "0             0.783          0.217  \n",
       "1             0.783          0.217  \n",
       "2             0.820          0.000  \n",
       "3             0.820          0.000  \n",
       "4             0.820          0.000  \n",
       "...             ...            ...  \n",
       "2256          0.781          0.219  \n",
       "2257          0.781          0.219  \n",
       "2258          0.781          0.219  \n",
       "2259          0.781          0.219  \n",
       "2260          0.527          0.473  \n",
       "\n",
       "[2261 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_sentences, columns=['utterance idx', 'sentence_neg', 'sentence_neu' ,'sentence_pos', 'utterance_neg', 'utterance_neu', 'utterance_pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overal context score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49\n",
      "Confusion Matrix:\n",
      "[[42 11]\n",
      " [60 25]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.79      0.54        53\n",
      "           1       0.69      0.29      0.41        85\n",
      "\n",
      "    accuracy                           0.49       138\n",
      "   macro avg       0.55      0.54      0.48       138\n",
      "weighted avg       0.59      0.49      0.46       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence specific context score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53\n",
      "Confusion Matrix:\n",
      "[[106 161]\n",
      " [ 54 132]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.40      0.50       267\n",
      "           1       0.45      0.71      0.55       186\n",
      "\n",
      "    accuracy                           0.53       453\n",
      "   macro avg       0.56      0.55      0.52       453\n",
      "weighted avg       0.58      0.53      0.52       453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(Xs_train, ys_train)\n",
    "\n",
    "# Predict on the test data\n",
    "ys_pred = model.predict(Xs_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(ys_test, ys_pred)\n",
    "conf_matrix = confusion_matrix(ys_test, ys_pred)\n",
    "report = classification_report(ys_test, ys_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
