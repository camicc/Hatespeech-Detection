{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_Valder():\n",
    "    # Load VADER sentiment analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Load the JSON file into a DataFrame\n",
    "    file_path = 'data/sarcasm_data.json'\n",
    "    df = pd.read_json(file_path).transpose()\n",
    "\n",
    "    # Reset the index to turn the first element into a new column\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Define a function to apply sentiment analysis to a text\n",
    "    def get_sentiment(text):\n",
    "        return analyzer.polarity_scores(text)\n",
    "\n",
    "    # Apply sentiment analysis to the 'utterance' column\n",
    "    df['sentiment_utterance'] = df['utterance'].apply(get_sentiment)\n",
    "\n",
    "    # Apply sentiment analysis to the 'context' column\n",
    "    df['sentiment_context_all'] = df['context'].apply(get_sentiment)\n",
    "\n",
    "    # Apply sentiment analysis to each sentence in the 'context' column\n",
    "    df['sentiment_context_per_sentence'] = df['context'].apply(lambda context: [get_sentiment(sentence) for sentence in context])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add one extra predictor as an array call \"sentiment_features\" (logic then is One-Hot encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U : Uterance sentiment\n",
    "# oC : Overall context sentiment\n",
    "# pC : Per sentence context sentiment\n",
    "\n",
    "# Add 1 with compound // Add 2 without it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments with pos, neu, neg and compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        [0.0, 0.783, 0.217, 0.3612]\n",
       " 1          [0.18, 0.82, 0.0, -0.296]\n",
       " 2               [0.0, 1.0, 0.0, 0.0]\n",
       " 3      [0.058, 0.851, 0.091, 0.4215]\n",
       " 4               [0.0, 1.0, 0.0, 0.0]\n",
       "                    ...              \n",
       " 685     [0.102, 0.898, 0.0, -0.5106]\n",
       " 686      [0.0, 0.858, 0.142, 0.3595]\n",
       " 687      [0.0, 0.763, 0.237, 0.4215]\n",
       " 688      [0.0, 0.781, 0.219, 0.4215]\n",
       " 689       [0.0, 0.527, 0.473, 0.659]\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg', 'utterance_neu', 'utterance_pos', 'utterance_compound'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_data_Valder()\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df['sentiment_utterance'].apply(lambda x: list(x.values()))\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "\n",
    "# Transpose the dataframe to get the orignal json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_sentiment_U1.json')\n",
    "\n",
    "df.iloc[-1], utterance_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uterance sentiments with pos, neu, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        [0.0, 0.783, 0.217]\n",
       " 1          [0.18, 0.82, 0.0]\n",
       " 2            [0.0, 1.0, 0.0]\n",
       " 3      [0.058, 0.851, 0.091]\n",
       " 4            [0.0, 1.0, 0.0]\n",
       "                ...          \n",
       " 685      [0.102, 0.898, 0.0]\n",
       " 686      [0.0, 0.858, 0.142]\n",
       " 687      [0.0, 0.763, 0.237]\n",
       " 688      [0.0, 0.781, 0.219]\n",
       " 689      [0.0, 0.527, 0.473]\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg', 'utterance_neu', 'utterance_pos'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_data_Valder()\n",
    "\n",
    "def remove_compound(dict):\n",
    "    return {key: value for key, value in dict.items() if key != 'compound'}\n",
    "\n",
    "# Apply the function to the 'sentiment_utterance' columns\n",
    "df['sentiment_utterance'] = df['sentiment_utterance'].apply(remove_compound)\n",
    "df['sentiment_features'] = df['sentiment_utterance'].apply(lambda x: list(x.values())) \n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_sentiment_U2.json')\n",
    "\n",
    "df.iloc[-1], utterance_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valder sentiment context overall + utterance with pos, neu, neg and compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        [0.0, 0.783, 0.217, 0.3612, 0.0, 1.0, 0.0, 0.0]\n",
       " 1      [0.18, 0.82, 0.0, -0.296, 0.0, 0.871, 0.129, 0...\n",
       " 2       [0.0, 1.0, 0.0, 0.0, 0.143, 0.857, 0.0, -0.4874]\n",
       " 3      [0.058, 0.851, 0.091, 0.4215, 0.0, 0.906, 0.09...\n",
       " 4      [0.0, 1.0, 0.0, 0.0, 0.097, 0.815, 0.088, 0.1513]\n",
       "                              ...                        \n",
       " 685     [0.102, 0.898, 0.0, -0.5106, 0.0, 1.0, 0.0, 0.0]\n",
       " 686    [0.0, 0.858, 0.142, 0.3595, 0.062, 0.751, 0.18...\n",
       " 687    [0.0, 0.763, 0.237, 0.4215, 0.506, 0.494, 0.0,...\n",
       " 688      [0.0, 0.781, 0.219, 0.4215, 0.0, 1.0, 0.0, 0.0]\n",
       " 689    [0.0, 0.527, 0.473, 0.659, 0.159, 0.736, 0.105...\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg',\n",
       "  'utterance_neu',\n",
       "  'utterance_pos',\n",
       "  'utterance_compound',\n",
       "  'context_neg',\n",
       "  'context_neu',\n",
       "  'context_pos',\n",
       "  'context_compound'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_Valder()\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "context_keys = ['context_' + key for key in df['sentiment_context_all'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "keys_list = utterance_keys + context_keys\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df.apply(lambda row: list(row['sentiment_utterance'].values()) + list(row['sentiment_context_all'].values()), axis=1)\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "# Save the DataFrame to a new JSON file\n",
    "df.to_json('sarcasm_data_sentiment_UoC1.json')\n",
    "\n",
    "df.iloc[-1], keys_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valder sentiment context overall + utterance with pos, neu, neg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0            [0.0, 0.783, 0.217, 0.0, 1.0, 0.0]\n",
       " 1          [0.18, 0.82, 0.0, 0.0, 0.871, 0.129]\n",
       " 2            [0.0, 1.0, 0.0, 0.143, 0.857, 0.0]\n",
       " 3      [0.058, 0.851, 0.091, 0.0, 0.906, 0.094]\n",
       " 4          [0.0, 1.0, 0.0, 0.097, 0.815, 0.088]\n",
       "                          ...                   \n",
       " 685          [0.102, 0.898, 0.0, 0.0, 1.0, 0.0]\n",
       " 686    [0.0, 0.858, 0.142, 0.062, 0.751, 0.187]\n",
       " 687      [0.0, 0.763, 0.237, 0.506, 0.494, 0.0]\n",
       " 688          [0.0, 0.781, 0.219, 0.0, 1.0, 0.0]\n",
       " 689    [0.0, 0.527, 0.473, 0.159, 0.736, 0.105]\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg',\n",
       "  'utterance_neu',\n",
       "  'utterance_pos',\n",
       "  'context_neg',\n",
       "  'context_neu',\n",
       "  'context_pos'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_Valder()\n",
    "\n",
    "def remove_compound(dict):\n",
    "    return {key: value for key, value in dict.items() if key != 'compound'}\n",
    "\n",
    "# Apply the function to the 'sentiment_utterance' and 'sentiment_context_all' columns\n",
    "df['sentiment_utterance'] = df['sentiment_utterance'].apply(remove_compound)\n",
    "df['sentiment_context_all'] = df['sentiment_context_all'].apply(remove_compound)\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "context_keys = ['context_' + key for key in df['sentiment_context_all'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "keys_list = utterance_keys + context_keys\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df['sentiment_utterance'].apply(lambda x: list(x.values())) + df['sentiment_context_all'].apply(lambda x: list(x.values()))\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "df.to_json('sarcasm_data_sentiment_UoC2.json')\n",
    "\n",
    "df.iloc[-1] , keys_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valder sentiment utterance + contex_per_sentence with pos, neu, neg and compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      [0.0, 0.783, 0.217, 0.3612, 0.0, 1.0, 0.0, 0.0...\n",
       " 1      [0.18, 0.82, 0.0, -0.296, 0.0, 0.705, 0.295, 0...\n",
       " 2      [0.0, 1.0, 0.0, 0.0, 0.268, 0.732, 0.0, -0.296...\n",
       " 3      [0.058, 0.851, 0.091, 0.4215, 0.0, 1.0, 0.0, 0...\n",
       " 4      [0.0, 1.0, 0.0, 0.0, 0.202, 0.439, 0.36, 0.421...\n",
       "                              ...                        \n",
       " 685    [0.102, 0.898, 0.0, -0.5106, 0.0, 1.0, 0.0, 0....\n",
       " 686    [0.0, 0.858, 0.142, 0.3595, 0.0, 1.0, 0.0, 0.0...\n",
       " 687    [0.0, 0.763, 0.237, 0.4215, 0.0, 1.0, 0.0, 0.0...\n",
       " 688    [0.0, 0.781, 0.219, 0.4215, 0.0, 1.0, 0.0, 0.0...\n",
       " 689    [0.0, 0.527, 0.473, 0.659, 0.159, 0.736, 0.105...\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg',\n",
       "  'utterance_neu',\n",
       "  'utterance_pos',\n",
       "  'utterance_compound',\n",
       "  'context_1_neg',\n",
       "  'context_1_neu',\n",
       "  'context_1_pos',\n",
       "  'context_1_compound',\n",
       "  'context_2_neg',\n",
       "  'context_2_neu',\n",
       "  'context_2_pos',\n",
       "  'context_2_compound',\n",
       "  'context_3_neg',\n",
       "  'context_3_neu',\n",
       "  'context_3_pos',\n",
       "  'context_3_compound'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to extract the 'neg', 'neu', 'pos', and 'compound' values from the first three dictionaries in a list\n",
    "def extract_values(sentences):\n",
    "    # Ensure the list has at least 3 dictionaries, padding if necessary\n",
    "    sentences.extend([{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound': 0.0}] * (3 - len(sentences)))\n",
    "    # Extract the values from the first 3 dictionaries\n",
    "    return [value for sentence in sentences[:3] for key, value in sentence.items()]\n",
    "\n",
    "df = get_data_Valder()\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "context_per_sentence_keys = [f\"context_{i}_{key}\" for i in range(1, 4) for key in ['neg', 'neu', 'pos', 'compound']]\n",
    "keys_list = utterance_keys + context_per_sentence_keys\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df.apply(lambda row: list(row['sentiment_utterance'].values()) + extract_values(row['sentiment_context_per_sentence']), axis=1)\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "# Save the DataFrame to a new JSON file\n",
    "df.to_json('sarcasm_data_sentiment_UpC1.json')\n",
    "\n",
    "df.iloc[-1], keys_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valder sentiment utterance + contex_per_sentence with pos, neu, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      [0.0, 0.783, 0.217, 0.0, 1.0, 0.0, 0.0, 1.0, 0...\n",
       " 1      [0.18, 0.82, 0.0, 0.0, 0.705, 0.295, 0.0, 0.30...\n",
       " 2      [0.0, 1.0, 0.0, 0.268, 0.732, 0.0, 0.0, 1.0, 0...\n",
       " 3      [0.058, 0.851, 0.091, 0.0, 1.0, 0.0, 0.0, 0.58...\n",
       " 4      [0.0, 1.0, 0.0, 0.202, 0.439, 0.36, 0.356, 0.6...\n",
       "                              ...                        \n",
       " 685    [0.102, 0.898, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0...\n",
       " 686    [0.0, 0.858, 0.142, 0.0, 1.0, 0.0, 0.0, 1.0, 0...\n",
       " 687    [0.0, 0.763, 0.237, 0.0, 1.0, 0.0, 0.506, 0.49...\n",
       " 688    [0.0, 0.781, 0.219, 0.0, 1.0, 0.0, 0.0, 1.0, 0...\n",
       " 689    [0.0, 0.527, 0.473, 0.159, 0.736, 0.105, 0.0, ...\n",
       " Name: sentiment_features, Length: 690, dtype: object,\n",
       " ['utterance_neg',\n",
       "  'utterance_neu',\n",
       "  'utterance_pos',\n",
       "  'context_1_neg',\n",
       "  'context_1_neu',\n",
       "  'context_1_pos',\n",
       "  'context_2_neg',\n",
       "  'context_2_neu',\n",
       "  'context_2_pos',\n",
       "  'context_3_neg',\n",
       "  'context_3_neu',\n",
       "  'context_3_pos'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to extract the 'neg', 'neu', 'pos', and 'compound' values from the first three dictionaries in a list\n",
    "def extract_values(sentences):\n",
    "    # Ensure the list has at least 3 dictionaries, padding if necessary\n",
    "    sentences.extend([{'neg': 0.0, 'neu': 0.0, 'pos': 0.0}] * (3 - len(sentences)))\n",
    "    # Extract the values from the first 3 dictionaries\n",
    "    return [value for sentence in sentences[:3] for key, value in sentence.items()]\n",
    "\n",
    "def remove_compound_1(dict):\n",
    "    return {key: value for key, value in dict.items() if key != 'compound'}\n",
    "def remove_compound_2(sentences):\n",
    "    return [{key: value for key, value in sentence.items() if key != 'compound'} for sentence in sentences]\n",
    "\n",
    "df = get_data_Valder()\n",
    "\n",
    "df['sentiment_utterance'] = df['sentiment_utterance'].apply(remove_compound_1)\n",
    "df['sentiment_context_per_sentence'] = df['sentiment_context_per_sentence'].apply(remove_compound_2)\n",
    "\n",
    "# Get the keys from the dictionaries and add a prefix\n",
    "utterance_keys = ['utterance_' + key for key in df['sentiment_utterance'].apply(lambda x: list(x.keys())).iloc[0]]\n",
    "context_per_sentence_keys = [f\"context_{i}_{key}\" for i in range(1, 4) for key in ['neg', 'neu', 'pos']]\n",
    "keys_list = utterance_keys + context_per_sentence_keys\n",
    "\n",
    "# Transform the dictionaries into arrays of scores\n",
    "df['sentiment_features'] = df.apply(lambda row: list(row['sentiment_utterance'].values()) + extract_values(row['sentiment_context_per_sentence']), axis=1)\n",
    "\n",
    "# Transpose the dataframe to get the original json format\n",
    "df = df.transpose()\n",
    "\n",
    "# Save the DataFrame to a new JSON file\n",
    "df.to_json('sarcasm_data_sentiment_UpC2.json')\n",
    "\n",
    "df.iloc[-1], keys_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harmann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "def hartmann_sentiment(text):\n",
    "    text = classifier(text)\n",
    "    # Assuming 'text' is already defined and contains the necessary data\n",
    "    sentiments = [text[0][i]['score'] for i in range(6)]\n",
    "    sentiment = np.argmax(sentiments)\n",
    "    return sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HateSpeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
